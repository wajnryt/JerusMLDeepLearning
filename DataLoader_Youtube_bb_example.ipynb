{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataLoader_Youtube_bb_example.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wajnryt/JerusMLDeepLearning2019/blob/master/DataLoader_Youtube_bb_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmB8AVkNnO8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "plt.ion()   # interactive mode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYwllFjJMWRn",
        "colab_type": "code",
        "outputId": "c83f7a36-3c2a-4358-a8f4-0c801b844dcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_b1qft7BMhCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "basedir = '/content/gdrive/My Drive/videos_2/yt_bb_detection_train'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfjUO4tdOSeT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import imageio\n",
        "from PIL import Image\n",
        "\n",
        "class InstanceDataset(Dataset):\n",
        "    def __init__(self, basedir, transform=None, force=False):\n",
        "        super().__init__()\n",
        "        self.transform = transform\n",
        "        cach_file = os.path.join(basedir, 'data.csv')\n",
        "        if not force and os.path.exists(cach_file):\n",
        "          self.data = pd.read_csv(cach_file)\n",
        "          print('load from csv')\n",
        "          return\n",
        "        print('start glob')\n",
        "        files = glob.glob(os.path.join(basedir ,'*','*','*.jpg'))\n",
        "        print('finish glob')\n",
        "        self.data = pd.DataFrame([self._split_file(f) for f in files], \n",
        "                            columns=['class_id', 'instance_id', 'file_path'])\n",
        "        self.data.to_csv(cach_file)\n",
        "        print('finish sort')\n",
        "        \n",
        "    def _split_file(self, f):\n",
        "        parts = f.split(os.sep)[-3:-1]\n",
        "        return parts[0], parts[1], f \n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      dat = self.data.iloc[index]\n",
        "      img = Image.open(dat['file_path'])\n",
        "      if self.transform:\n",
        "        img = self.transform(img)\n",
        "      return (img, dat['class_id'], dat['instance_id'])\n",
        "              \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9gm8gUJpdUm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3493b0b2-b61d-4e3e-ce8f-fe0616ddf7b4"
      },
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((256,256)),\n",
        "        #transforms.Pad(256),\n",
        "        #transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "dataset = InstanceDataset(basedir, data_transforms['train'], True)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=3,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "\n",
        "device = torch.device(\"cuda:0\")\n"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start glob\n",
            "finish glob\n",
            "finish sort\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Min9msub4ghn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(dataset.data['instance_id'].unique()), ' unique instances')\n",
        "print(len(dataset.data['class_id'].unique()), ' classes')\n",
        "print(len(dataset) , ' images')\n",
        "import numpy as np\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.hist(dataset.data['class_id'].values.astype(int), normed=True)\n",
        "plt.title('images per class')\n",
        "plt.xlabel('class id')\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "_, count = np.unique(dataset.data['instance_id'], return_counts=True)\n",
        "plt.hist(count, normed=True)\n",
        "plt.title('images per instance')\n",
        "plt.xlabel('images per instance')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWZ2id8AeaYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "#example. \n",
        "# this is not how you're supposed to use dataset!\n",
        "# you should axes it via torch DataLoader...\n",
        "# never dirrectly call __getitem__, or access the members (dataset.data)\n",
        "\n",
        "print(len(dataset))\n",
        "im, class_id, instance_id = dataset.__getitem__(500)\n",
        "\n",
        "\n",
        "#just for fun, lets find another one of this guy\n",
        "thisguy = dataset.data[dataset.data['instance_id']==instance_id]\n",
        "for ind, dat in thisguy.iterrows():\n",
        "  plt.figure()\n",
        "  plt.imshow(imageio.imread(dat['file_path']))\n",
        "  plt.title(f'class id {dat[\"class_id\"]}, instance {dat[\"instance_id\"]}')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQAy_C0wp_Go",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes, instance= next(iter(dataloader))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs,3)\n",
        "plt.figure(figsize=(15,15))\n",
        "imshow(out)#, title=[class_names[x] for x in classes])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}