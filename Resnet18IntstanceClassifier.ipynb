{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataLoader_Youtube_bb_example.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wajnryt/JerusMLDeepLearning2019/blob/David/Resnet18IntstanceClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmB8AVkNnO8q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "186ce15b-e2df-448f-b1d0-96ee7d3df0f8"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_b1qft7BMhCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "basedir = '/content/gdrive/My Drive/videos_2/yt_bb_detection_train'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfjUO4tdOSeT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import imageio\n",
        "from PIL import Image\n",
        "\n",
        "class InstanceDataset(Dataset):\n",
        "    def __init__(self, basedir, transform=None, force=False):\n",
        "        super().__init__()\n",
        "        self.transform = transform\n",
        "        cach_file = os.path.join(basedir, 'data.csv')\n",
        "        if not force and os.path.exists(cach_file):\n",
        "          self.data = pd.read_csv(cach_file)\n",
        "          print('load from csv')\n",
        "          return\n",
        "        print('start glob')\n",
        "        files = glob.glob(os.path.join(basedir ,'*','*','*.jpg'))\n",
        "        print('finish glob')\n",
        "        self.data = pd.DataFrame([self._split_file(f) for f in files], \n",
        "                            columns=['class_id',  'file_path'])\n",
        "        self.data.to_csv(cach_file)\n",
        "        print('finish sort')\n",
        "        \n",
        "    def _split_file(self, f):\n",
        "        parts = f.split(os.sep)[-3:-1]\n",
        "        return parts[0], f \n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      dat = self.data.iloc[index]\n",
        "      img = Image.open(dat['file_path'])\n",
        "      if self.transform:\n",
        "        img = self.transform(img)\n",
        "      return (img, dat['class_id'], dat['instance_id'])\n",
        "              \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9gm8gUJpdUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((256,256)),\n",
        "        #transforms.Pad(256),\n",
        "        #transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# dataset = InstanceDataset(basedir, data_transforms['train'], True)\n",
        "# dataloader = torch.utils.data.DataLoader(dataset, batch_size=3,\n",
        "#                                              shuffle=True, num_workers=4)\n",
        "\n",
        "device = torch.device(\"cuda:0\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb4S9NmiQYco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
        "                                  else \"cpu\")\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.003)\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2weIaXVOdfTv",
        "colab_type": "code",
        "outputId": "528aa245-95d0-46f1-913d-56a36e57c4ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "# train_set = ImageFolder(root='/content/JerusML/My Drive/JerusML/Grayscale/', transform=ToTensor())\n",
        "# test_set = ImageFolder(root='/content/JerusML/My Drive/JerusML/GrayscaleTEST/', transform=ToTensor())\n",
        "\n",
        "batch_size = 3\n",
        "dataset_train = InstanceDataset(basedir, data_transforms['train'], True)\n",
        "dataset_val = InstanceDataset(basedir, data_transforms['val'], True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset_val, batch_size=batch_size,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "\n",
        "\n",
        "\n",
        "# train_loader = torch.utils.data.DataLoader(\n",
        "#                  dataset=train_set,\n",
        "#                  batch_size=batch_size,\n",
        "#                  shuffle=True)\n",
        "# test_loader = torch.utils.data.DataLoader(\n",
        "#                 dataset=test_set,\n",
        "#                 batch_size=batch_size,\n",
        "#                 shuffle=False)\n",
        "\n",
        "\n",
        "print ('==>>> total trainning batch number: {}'.format(len(train_loader)))\n",
        "print ('==>>> total testing batch number: {}'.format(len(test_loader)))\n",
        "\n",
        "## network\n",
        "class MLPNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLPNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 500)\n",
        "        self.fc2 = nn.Linear(500, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "    \n",
        "    def name(self):\n",
        "        return \"MLP\"\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 20, 5, 1, 2)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1, 2)\n",
        "        self.fc1 = nn.Linear(164*218*50, 3)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        print(x.shape)\n",
        "        x = x.view(-1, 164*218*50)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "    \n",
        "    def name(self):\n",
        "        return \"LeNet\"\n",
        "\n",
        "## training\n",
        "model = models.resnet18()\n",
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    model = model.cuda()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(10):\n",
        "    # trainning\n",
        "    ave_loss = 0\n",
        "    for batch_idx, (x, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        if use_cuda:\n",
        "            x, target = x.cuda(), target.cuda()\n",
        "        x, target = Variable(x), Variable(target)\n",
        "        out = model(x)\n",
        "        loss = criterion(out, target)\n",
        "        ave_loss = ave_loss * 0.9 + loss.data * 0.1\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if (batch_idx+1) % 100 == 0 or (batch_idx+1) == len(train_loader):\n",
        "            print ('==>>> epoch: {}, batch index: {}, train loss: {:.6f}'.format(\n",
        "                epoch, batch_idx+1, ave_loss))\n",
        "    # testing\n",
        "    correct_cnt, ave_loss = 0, 0\n",
        "    total_cnt = 0\n",
        "    for batch_idx, (x, target) in enumerate(test_loader):\n",
        "        if use_cuda:\n",
        "            x, target = x.cuda(), target.cuda()\n",
        "        x, target = Variable(x, volatile=True), Variable(target, volatile=True)\n",
        "        out = model(x)\n",
        "        loss = criterion(out, target)\n",
        "        _, pred_label = torch.max(out.data, 1)\n",
        "        total_cnt += x.data.size()[0]\n",
        "        correct_cnt += (pred_label == target.data).sum()\n",
        "        # smooth average\n",
        "        ave_loss = ave_loss * 0.9 + loss.data * 0.1\n",
        "        \n",
        "        if(batch_idx+1) % 100 == 0 or (batch_idx+1) == len(test_loader):\n",
        "            print ('==>>> epoch: {}, batch index: {}, test loss: {:.6f}, acc: {:.3f}'.format(\n",
        "                epoch, batch_idx+1, ave_loss,float(correct_cnt)/total_cnt))\n",
        "\n",
        "torch.save(model.state_dict(), model.name())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start glob\n",
            "finish glob\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Min9msub4ghn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(len(dataset.data['instance_id'].unique()), ' unique instances')\n",
        "# print(len(dataset.data['class_id'].unique()), ' classes')\n",
        "# print(len(dataset) , ' images')\n",
        "# import numpy as np\n",
        "\n",
        "# plt.figure(figsize=(15,15))\n",
        "# plt.hist(dataset.data['class_id'].values.astype(int), normed=True)\n",
        "# plt.title('images per class')\n",
        "# plt.xlabel('class id')\n",
        "\n",
        "# plt.figure(figsize=(15,15))\n",
        "# _, count = np.unique(dataset.data['instance_id'], return_counts=True)\n",
        "# plt.hist(count, normed=True)\n",
        "# plt.title('images per instance')\n",
        "# plt.xlabel('images per instance')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWZ2id8AeaYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# %matplotlib inline\n",
        "# #example. \n",
        "# # this is not how you're supposed to use dataset!\n",
        "# # you should axes it via torch DataLoader...\n",
        "# # never dirrectly call __getitem__, or access the members (dataset.data)\n",
        "\n",
        "# print(len(dataset))\n",
        "# im, class_id, instance_id = dataset.__getitem__(500)\n",
        "\n",
        "\n",
        "# #just for fun, lets find another one of this guy\n",
        "# thisguy = dataset.data[dataset.data['instance_id']==instance_id]\n",
        "# for ind, dat in thisguy.iterrows():\n",
        "#   plt.figure()\n",
        "#   plt.imshow(imageio.imread(dat['file_path']))\n",
        "#   plt.title(f'class id {dat[\"class_id\"]}, instance {dat[\"instance_id\"]}')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQAy_C0wp_Go",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def imshow(inp, title=None):\n",
        "#     \"\"\"Imshow for Tensor.\"\"\"\n",
        "#     inp = inp.numpy().transpose((1, 2, 0))\n",
        "#     mean = np.array([0.485, 0.456, 0.406])\n",
        "#     std = np.array([0.229, 0.224, 0.225])\n",
        "#     inp = std * inp + mean\n",
        "#     inp = np.clip(inp, 0, 1)\n",
        "#     plt.imshow(inp)\n",
        "#     if title is not None:\n",
        "#         plt.title(title)\n",
        "#     plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "# # Get a batch of training data\n",
        "# inputs, classes, instance= next(iter(dataloader))\n",
        "\n",
        "# # Make a grid from batch\n",
        "# out = torchvision.utils.make_grid(inputs,3)\n",
        "# plt.figure(figsize=(15,15))\n",
        "# imshow(out)#, title=[class_names[x] for x in classes])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iEdbhgK1ZtL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "outputId": "e7eee57c-ca51-4168-d89c-14da3aadb5e9"
      },
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# from torch.autograd import Variable\n",
        "# import torchvision.datasets as dset\n",
        "# import torchvision.transforms as transforms\n",
        "# import torch.nn.functional as F\n",
        "# import torch.optim as optim\n",
        "# from torchvision.datasets import ImageFolder\n",
        "# from torchvision.transforms import ToTensor\n",
        "\n",
        "\n",
        "# batch_size = 3\n",
        "# dataset_train = InstanceDataset(basedir,dataset_train, True)\n",
        "# dataset_val = InstanceDataset(basedir, dataset_train, True)\n",
        "\n",
        "# train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size,\n",
        "#                                              shuffle=True, num_workers=4)\n",
        "\n",
        "# test_loader = torch.utils.data.DataLoader(dataset_val, batch_size=batch_size,\n",
        "#                                              shuffle=True, num_workers=4)\n",
        "\n",
        "# print ('==>>> total trainning batch number: {}'.format(len(train_loader)))\n",
        "# print ('==>>> total testing batch number: {}'.format(len(test_loader)))\n",
        "\n",
        "\n",
        "# model = models.resnet18()\n",
        "\n",
        "# epochs = 1\n",
        "# steps = 0\n",
        "# running_loss = 0\n",
        "# print_every = 10\n",
        "# train_losses, test_losses = [], []\n",
        "# for epoch in range(epochs):\n",
        "#     for inputs, labels in trainloader:\n",
        "#         steps += 1\n",
        "#         inputs, labels = inputs.to(device), labels.to(device)\n",
        "#         optimizer.zero_grad()\n",
        "#         logps = model.forward(inputs)\n",
        "#         loss = criterion(logps, labels)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         running_loss += loss.item()\n",
        "        \n",
        "#         if steps % print_every == 0:\n",
        "#             test_loss = 0\n",
        "#             accuracy = 0\n",
        "#             model.eval()\n",
        "#             with torch.no_grad():\n",
        "#                 for inputs, labels in testloader:\n",
        "#                     inputs, labels = inputs.to(device), labels.to(device)\n",
        "#                     logps = model.forward(inputs)\n",
        "#                     batch_loss = criterion(logps, labels)\n",
        "#                     test_loss += batch_loss.item()\n",
        "                    \n",
        "#                     ps = torch.exp(logps)\n",
        "#                     top_p, top_class = ps.topk(1, dim=1)\n",
        "#                     equals =  top_class == labels.view(*top_class.shape)\n",
        "#                     accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "#             train_losses.append(running_loss/len(trainloader))\n",
        "#             test_losses.append(test_loss/len(testloader))                    \n",
        "#             print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
        "#                   f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
        "#                   f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
        "#                   f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
        "#             running_loss = 0\n",
        "#             model.train()\n",
        "# torch.save(model, 'resnet18i.pth')"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start glob\n",
            "finish glob\n",
            "finish sort\n",
            "start glob\n",
            "finish glob\n",
            "finish sort\n",
            "==>>> total trainning batch number: 33004\n",
            "==>>> total testing batch number: 33004\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-116-ca70f51091a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"KeyError:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 99, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 99, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-97-aea49acb5047>\", line 32, in __getitem__\n    img = self.transform(img)\n  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\", line 61, in __call__\n    img = t(img)\n  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\", line 164, in __call__\n    return F.normalize(tensor, self.mean, self.std, self.inplace)\n  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\", line 208, in normalize\n    tensor.sub_(mean[:, None, None]).div_(std[:, None, None])\nRuntimeError: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 0\n"
          ]
        }
      ]
    }
  ]
}